{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Convolution in module mxnet.symbol:\n",
      "\n",
      "Convolution(*args, **kwargs)\n",
      "    Compute *N*-D convolution on *(N+2)*-D input.\n",
      "    \n",
      "    In the 2-D convolution, given input data with shape *(batch_size,\n",
      "    channel, height, width)*, the output is computed by\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "       out[n,i,:,:] = bias[i] + \\sum_{j=0}^{num\\_filter} data[n,j,:,:] \\star\n",
      "       weight[i,j,:,:]\n",
      "    \n",
      "    where :math:`\\star` is the 2-D cross-correlation operator.\n",
      "    \n",
      "    For general 2-D convolution, the shapes are\n",
      "    \n",
      "    - **data**: *(batch_size, channel, height, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0], kernel[1])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_height, out_width)*.\n",
      "    \n",
      "    Define::\n",
      "    \n",
      "      f(x,k,p,s,d) = floor((x+2*p-d*(k-1)-1)/s)+1\n",
      "    \n",
      "    then we have::\n",
      "    \n",
      "      out_height=f(height, kernel[0], pad[0], stride[0], dilate[0])\n",
      "      out_width=f(width, kernel[1], pad[1], stride[1], dilate[1])\n",
      "    \n",
      "    If ``no_bias`` is set to be true, then the ``bias`` term is ignored.\n",
      "    \n",
      "    The default data ``layout`` is *NCHW*, namely *(batch_size, channel, height,\n",
      "    width)*. We can choose other layouts such as *NHWC*.\n",
      "    \n",
      "    If ``num_group`` is larger than 1, denoted by *g*, then split the input ``data``\n",
      "    evenly into *g* parts along the channel axis, and also evenly split ``weight``\n",
      "    along the first dimension. Next compute the convolution on the *i*-th part of\n",
      "    the data with the *i*-th weight part. The output is obtained by concatenating all\n",
      "    the *g* results.\n",
      "    \n",
      "    1-D convolution does not have *height* dimension but only *width* in space.\n",
      "    \n",
      "    - **data**: *(batch_size, channel, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_width)*.\n",
      "    \n",
      "    3-D convolution adds an additional *depth* dimension besides *height* and\n",
      "    *width*. The shapes are\n",
      "    \n",
      "    - **data**: *(batch_size, channel, depth, height, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0], kernel[1], kernel[2])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_depth, out_height, out_width)*.\n",
      "    \n",
      "    Both ``weight`` and ``bias`` are learnable parameters.\n",
      "    \n",
      "    There are other options to tune the performance.\n",
      "    \n",
      "    - **cudnn_tune**: enable this option leads to higher startup time but may give\n",
      "      faster speed. Options are\n",
      "    \n",
      "      - **off**: no tuning\n",
      "      - **limited_workspace**:run test and pick the fastest algorithm that doesn't\n",
      "        exceed workspace limit.\n",
      "      - **fastest**: pick the fastest algorithm and ignore workspace limit.\n",
      "      - **None** (default): the behavior is determined by environment variable\n",
      "        ``MXNET_CUDNN_AUTOTUNE_DEFAULT``. 0 for off, 1 for limited workspace\n",
      "        (default), 2 for fastest.\n",
      "    \n",
      "    - **workspace**: A large number leads to more (GPU) memory usage but may improve\n",
      "      the performance.\n",
      "    \n",
      "    \n",
      "    \n",
      "    Defined in src/operator/convolution.cc:L154\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : Symbol\n",
      "        Input data to the ConvolutionOp.\n",
      "    weight : Symbol\n",
      "        Weight matrix.\n",
      "    bias : Symbol\n",
      "        Bias parameter.\n",
      "    kernel : Shape(tuple), required\n",
      "        convolution kernel size: (h, w) or (d, h, w)\n",
      "    stride : Shape(tuple), optional, default=()\n",
      "        convolution stride: (h, w) or (d, h, w)\n",
      "    dilate : Shape(tuple), optional, default=()\n",
      "        convolution dilate: (h, w) or (d, h, w)\n",
      "    pad : Shape(tuple), optional, default=()\n",
      "        pad for convolution: (h, w) or (d, h, w)\n",
      "    num_filter : int (non-negative), required\n",
      "        convolution filter(channel) number\n",
      "    num_group : int (non-negative), optional, default=1\n",
      "        Number of group partitions.\n",
      "    workspace : long (non-negative), optional, default=1024\n",
      "        Maximum temporary workspace allowed for convolution (MB).\n",
      "    no_bias : boolean, optional, default=False\n",
      "        Whether to disable bias parameter.\n",
      "    cudnn_tune : {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'\n",
      "        Whether to pick convolution algo by running performance test.\n",
      "    cudnn_off : boolean, optional, default=False\n",
      "        Turn off cudnn for this layer.\n",
      "    layout : {None, 'NCDHW', 'NCHW', 'NCW', 'NDHWC', 'NHWC'},optional, default='None'\n",
      "        Set layout for input, output and weight. Empty for\n",
      "        default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.\n",
      "    \n",
      "    name : string, optional.\n",
      "        Name of the resulting symbol.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Symbol\n",
      "        The result symbol.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "help(mx.sym.Convolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inception(input_layer):\n",
    "    conv1=mx.sym.Convolution()\n",
    "    conv2=\n",
    "    conv3=\n",
    "    pool=mx.sym.Pooling()\n",
    "    out= conv1+conv2+conv3+pool\n",
    "    return out\n",
    "\n",
    "date =mx.sym.Variable('data')\n",
    "layer1 = \n",
    "layer2 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx.viz.plot_network(layer2, shape={'data': (1,64,28,28)}) 3,14,14 -> 64,14,14\n",
    "mx."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
